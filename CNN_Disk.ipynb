{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN by reading batches of images from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to train a model with so many images that it couldn't be feasible to train them from RAM.  \n",
    "In that case, loading a group by a batch size might come handy.  \n",
    "  \n",
    "\n",
    "Here you will see how to do it by first loading the location of the images into a pandas dataframe, that could work as a \"database source\" and then reading it from disk, transform to grayscale, resize and turning it into a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image #http://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to load an image, transform to gray scale, resize and turn it into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rgbToG(img):\n",
    "    \"\"\"\n",
    "    Color to gray\n",
    "    \"\"\"\n",
    "    npImg=np.asarray(img)\n",
    "    r=0.2125\n",
    "    g=0.7154\n",
    "    b=0.0721\n",
    "    gsImg=r*npImg[:,:,0]+g*npImg[:,:,1]+b*npImg[:,:,2]\n",
    "    return gsImg\n",
    "def imgToGray(imgF,resize=True,w_h = (32,32)):\n",
    "    \"\"\"\n",
    "    Open Image and \n",
    "    \"\"\"\n",
    "    img=Image.open(imgF)\n",
    "    if resize==True:\n",
    "        img = img.resize(w_h,Image.ANTIALIAS)\n",
    "    imnp=np.asarray(img)\n",
    "    img.close() #Close opened image\n",
    "    ims=len(imnp.shape)\n",
    "    if ims == 3:\n",
    "        imgG=rgbToG(imnp)\n",
    "    elif ims ==2:\n",
    "        imgG=imnp\n",
    "    return imgG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define images repository and save the complete path plus the image to a list.  \n",
    "We define the y_labels dictionary to transform the name 'dog,cat' into a dummies array  \n",
    "that can be used by a softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Images source: https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "data='/home/bsaldivar/.../'\n",
    "\n",
    "y_labels={'cat':np.array([[1, 0]]),'dog':np.array([[0, 1]])}\n",
    "image_list = []\n",
    "\n",
    "for f in os.listdir(data):\n",
    "    target = f.split('.')[0]\n",
    "    file_full=data+f\n",
    "    image_list.append({'file':f,'file_full':file_full,'target':y_labels[target]})\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list into a dataframe and then show the its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           file                         file_full    target\n",
      "0  cat.1555.jpg  /home/bsaldivar/.../cat.1555.jpg  [[1, 0]]\n",
      "1  cat.9666.jpg  /home/bsaldivar/.../cat.9666.jpg  [[1, 0]]\n",
      "2  dog.7569.jpg  /home/bsaldivar/.../dog.7569.jpg  [[0, 1]]\n",
      "3  cat.5661.jpg  /home/bsaldivar/.../cat.5661.jpg  [[1, 0]]\n",
      "4  cat.5213.jpg  /home/bsaldivar/.../cat.5213.jpg  [[1, 0]]\n",
      "5  cat.7355.jpg  /home/bsaldivar/.../cat.7355.jpg  [[1, 0]]\n",
      "6  cat.7022.jpg  /home/bsaldivar/.../cat.7022.jpg  [[1, 0]]\n",
      "7  cat.3681.jpg  /home/bsaldivar/.../cat.3681.jpg  [[1, 0]]\n",
      "8  dog.7159.jpg  /home/bsaldivar/.../dog.7159.jpg  [[0, 1]]\n",
      "9  dog.9138.jpg  /home/bsaldivar/.../dog.9138.jpg  [[0, 1]]\n"
     ]
    }
   ],
   "source": [
    "image_df = pd.DataFrame(image_list)\n",
    "print(image_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open an image alone to see its dimensions and try our function to transform to gray and resize into a numpy array from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bsaldivar/.../train/cat.1555.jpg\n",
      "(199, 150)\n",
      "<class 'numpy.ndarray'> (32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f691887c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix = image_df.loc[0]['file_full']\n",
    "print(ix)\n",
    "pix = Image.open(ix)\n",
    "print(pix.size)\n",
    "pix.close()\n",
    "\n",
    "pix = imgToGray(ix,resize=True,w_h = (32,32))\n",
    "print(type(pix),pix.shape)\n",
    "plt.imshow(pix,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our by batch reading from disk and transform to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the limit number to just train from 20 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size=5\n",
    "limit=20\n",
    "for _ in range(0,limit,batch_size):\n",
    "    x_y = image_df.iloc[_:_+batch_size]\n",
    "    fx = x_y['file_full'].values\n",
    "    fy = x_y['target'].values\n",
    "\n",
    "    z = list(map(imgToGray,fx))\n",
    "    x = np.asarray(z)\n",
    "    x = x.reshape([x.shape[0],x.shape[1],x.shape[2],1])\n",
    "    \n",
    "    y = np.concatenate(fy,0)\n",
    "    \n",
    "    print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function to call it in a simpler way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n",
      "(5, 32, 32, 1) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "def df_x_y (df,x_label,y_label,batch_size=5,offset=0):\n",
    "    x_y = df.iloc[offset:offset+batch_size]\n",
    "    fx = x_y[x_label].values\n",
    "    fy = x_y[y_label].values\n",
    "    z = list(map(imgToGray,fx))\n",
    "    x = np.asarray(z)\n",
    "    x = x.reshape([x.shape[0],x.shape[1],x.shape[2],1])\n",
    "    y = np.concatenate(fy,0)\n",
    "    return x,y\n",
    "\n",
    "batch_size=5\n",
    "limit=20\n",
    "\n",
    "for _ in range(0,limit,batch_size):\n",
    "    x_,y_ = df_x_y (image_df,x_label='file_full',y_label='target',batch_size=5,offset=_)\n",
    "    print(x_.shape,y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define layers for construction of a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_previous_features(i_layer):\n",
    "    convx_dims = i_layer.get_shape().as_list()\n",
    "    output_features = 1\n",
    "    for dim in range(1,len(convx_dims)):\n",
    "        output_features=output_features*convx_dims[dim]\n",
    "    return output_features\n",
    "\n",
    "\n",
    "\n",
    "def conv(input_matrix,filter_size=3,layer_depth=8,\n",
    "              strides=[1,1,1,1],padding='SAME',\n",
    "              is_training=True,name_scope=\"lx\",\n",
    "              stddev_n = 0.05,\n",
    "             max_bool=False,max_kernel=[1,2,2,1],max_strides=[1,1,1,1], max_padding='SAME',\n",
    "             drop_out_bool=False,drop_out_ph=None,drop_out_v=None,decay=0.5\n",
    "             ):\n",
    "    with tf.name_scope(name_scope):\n",
    "        ims = input_matrix.get_shape().as_list()\n",
    "        input_depth=ims[len(ims)-1]\n",
    "        W = tf.Variable(tf.truncated_normal([filter_size,filter_size,input_depth,layer_depth], stddev=stddev_n),name='W')\n",
    "        b = tf.Variable(tf.constant(stddev_n, shape=[layer_depth]),name='b')\n",
    "        c = tf.add(tf.nn.conv2d(input_matrix, W, strides=strides, padding=padding),b,name='conv')\n",
    "        n = tf.contrib.layers.batch_norm(c, center=True, scale=True, is_training=is_training,decay=decay)\n",
    "        a = tf.nn.relu(n,name=\"activation\")\n",
    "        if max_bool==True:\n",
    "            out = tf.nn.max_pool(a, ksize=max_kernel,strides=max_strides, padding=max_padding,name='max')\n",
    "        else:\n",
    "            out = a\n",
    "        if drop_out_bool==True:\n",
    "            out_  = tf.nn.dropout(out, drop_out_ph)\n",
    "        else:\n",
    "            out_ = out\n",
    "        return out_\n",
    "\n",
    "\n",
    "def fc(input_matrix,n=22,norm=False,prev_conv=False,\n",
    "       stddev_n = 0.05,is_training=True,\n",
    "       name_scope='FC',drop_out_bool=False,drop_out_ph=None,drop_out_v=None,decay=0.5):\n",
    "    with tf.name_scope(name_scope):\n",
    "        cvpfx = get_previous_features(input_matrix)\n",
    "        if prev_conv==True:\n",
    "            im = tf.reshape(input_matrix, [-1, cvpfx])\n",
    "        else:\n",
    "            im = input_matrix\n",
    "        W = tf.Variable(tf.truncated_normal([cvpfx, n], stddev=stddev_n),name='W')\n",
    "        b = tf.Variable(tf.constant(stddev_n, shape=[n]),name='b') \n",
    "        fc = tf.add(tf.matmul(im, W),b,name=\"FC\")\n",
    "        if name_scope==\"FCL\":\n",
    "            out_ = fc\n",
    "        else:\n",
    "            if norm==True:\n",
    "                n = tf.contrib.layers.batch_norm(fc, center=True, scale=True, is_training=is_training,decay=decay)\n",
    "                out = tf.nn.relu(n,name=\"activation\")\n",
    "            else:\n",
    "                out = tf.nn.relu(fc,name=\"activation\")\n",
    "            if drop_out_bool==True:\n",
    "                out_  = tf.nn.dropout(out, drop_out_ph)\n",
    "            else:\n",
    "                out_ = out\n",
    "        return out_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(df,x_label,y_label,x_shape_,y_shape,\n",
    "          batch_size=5,limit=20,\n",
    "          iters=10,lr=0.001,save_model=True,save_name=None,restore_model=False,restore_name=None,v=False):\n",
    "    \"\"\"\n",
    "    df: Dataframe that contains the image location in the x_label column, and the target dummies array in the y_label\n",
    "    column. \n",
    "    x_shape_ and y_shape: shape of a batch for x and y, [None, 32,32,1] and [None,2] for grayscale channel 1, \n",
    "    and 2 target classes \n",
    "    v: for verbosity, if true show the loss progress\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    class_output = y_shape[1]\n",
    "    \n",
    "    x_shape=[None]\n",
    "    for _ in range(1,len(x_shape_)):\n",
    "        x_shape.append(x_shape_[_])\n",
    "    xi = tf.placeholder(tf.float32, shape=x_shape,name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None,class_output],name='y')\n",
    "    train_bool=tf.placeholder(bool,name='train_test')\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #Define the model here--DOWN\n",
    "    CV1 = conv(xi,filter_size=3,layer_depth=2,name_scope=\"CL1\",is_training=train_bool)\n",
    "    CV2 = conv(CV1,filter_size=3,layer_depth=2,name_scope=\"CL2\",is_training=train_bool)\n",
    "    prediction = fc(CV2,n=class_output,name_scope=\"FCL\",prev_conv=True)\n",
    "    #Define the model here--UP\n",
    "    \n",
    "    y_CNN = tf.nn.softmax(prediction,name='Softmax')\n",
    "    class_pred = tf.argmax(y_CNN,1,name='ClassPred')\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_CNN), reduction_indices=[1]),name=\"loss\")\n",
    "    \n",
    "    #The following three lines are required to make \"is_training\" work for normalization\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as s:\n",
    "        if restore_model==True:\n",
    "            if restore_name==None:\n",
    "                print(\"No model file specified\")\n",
    "                return\n",
    "            else:\n",
    "                saver.restore(s,restore_dir)\n",
    "        else:\n",
    "            s.run(init_op)\n",
    "        \n",
    "        \n",
    "        for __ in range(0,iters):\n",
    "            #Read and transform to a numpy array images from disk by block\n",
    "            for _ in range(0,limit,batch_size):\n",
    "                x,y = df_x_y (df,'file_full','target',batch_size=batch_size,offset=_)\n",
    "                fd={xi:x,y_:y,learning_rate:lr,train_bool:True}\n",
    "                _t,l = s.run([train_step,loss],feed_dict=fd)\n",
    "                if v==True:\n",
    "                    print(\"Batch\",_,\"Iter:\",__,\"Loss:\",l)\n",
    "            \n",
    "        if save_model==True:\n",
    "            if save_name==None:\n",
    "                print(\"No model specified, model not being saved\")\n",
    "                return\n",
    "            else:\n",
    "                save_path = saver.save(s, save_name)\n",
    "                print(\"Model saved in file: %s\" % save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Iter: 0 Loss: 0.422241\n",
      "Batch 5 Iter: 0 Loss: 0.986407\n",
      "Batch 10 Iter: 0 Loss: 2.02306\n",
      "Batch 15 Iter: 0 Loss: 1.489\n",
      "Batch 0 Iter: 1 Loss: 0.301701\n",
      "Batch 5 Iter: 1 Loss: 0.503432\n",
      "Batch 10 Iter: 1 Loss: 0.65972\n",
      "Batch 15 Iter: 1 Loss: 0.628321\n",
      "Batch 0 Iter: 2 Loss: 0.639722\n",
      "Batch 5 Iter: 2 Loss: 0.500898\n",
      "Batch 10 Iter: 2 Loss: 0.409604\n",
      "Batch 15 Iter: 2 Loss: 0.466021\n",
      "Batch 0 Iter: 3 Loss: 0.367195\n",
      "Batch 5 Iter: 3 Loss: 0.201632\n",
      "Batch 10 Iter: 3 Loss: 0.197201\n",
      "Batch 15 Iter: 3 Loss: 0.558277\n",
      "Batch 0 Iter: 4 Loss: 0.154518\n",
      "Batch 5 Iter: 4 Loss: 0.13012\n",
      "Batch 10 Iter: 4 Loss: 0.132147\n",
      "Batch 15 Iter: 4 Loss: 0.518349\n",
      "Batch 0 Iter: 5 Loss: 0.113399\n",
      "Batch 5 Iter: 5 Loss: 0.10281\n",
      "Batch 10 Iter: 5 Loss: 0.0989146\n",
      "Batch 15 Iter: 5 Loss: 0.287876\n",
      "Batch 0 Iter: 6 Loss: 0.10605\n",
      "Batch 5 Iter: 6 Loss: 0.0756181\n",
      "Batch 10 Iter: 6 Loss: 0.0848531\n",
      "Batch 15 Iter: 6 Loss: 0.136071\n",
      "Batch 0 Iter: 7 Loss: 0.112834\n",
      "Batch 5 Iter: 7 Loss: 0.0641526\n",
      "Batch 10 Iter: 7 Loss: 0.0733536\n",
      "Batch 15 Iter: 7 Loss: 0.0871756\n",
      "Batch 0 Iter: 8 Loss: 0.108459\n",
      "Batch 5 Iter: 8 Loss: 0.0523542\n",
      "Batch 10 Iter: 8 Loss: 0.0535746\n",
      "Batch 15 Iter: 8 Loss: 0.0677359\n",
      "Batch 0 Iter: 9 Loss: 0.0893725\n",
      "Batch 5 Iter: 9 Loss: 0.0378148\n",
      "Batch 10 Iter: 9 Loss: 0.0372809\n",
      "Batch 15 Iter: 9 Loss: 0.0589032\n"
     ]
    }
   ],
   "source": [
    "xs = [None,32,32,1]\n",
    "ys = [None,2]\n",
    "train(image_df,'file_image','target',xs,ys,iters=10,lr=0.001,save_model=False,save_name=None,restore_model=False,restore_name=None,v=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
